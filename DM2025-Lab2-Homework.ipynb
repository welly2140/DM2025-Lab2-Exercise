{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name: 魏士勛\n",
    "\n",
    "Student ID: 114062587\n",
    "\n",
    "GitHub ID: welly2140\n",
    "\n",
    "Kaggle name: wellywei\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![PrivateScore.png](./KaggleData/PrivateScore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "**Syntax:** `#` creates the largest heading (H1).\n",
    "\n",
    "---\n",
    "**Syntax:** `---` creates a horizontal rule (a separator line).\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "**Syntax:** `##` creates a secondary heading (H2).\n",
    "\n",
    "**Describe briefly each section, you can add graphs/charts to support your explanations.**\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "1. Remove URLs\n",
    "    * URLs carry little emotional meaning and are removed.\n",
    "\n",
    "2. Remove user mentions\n",
    "    * Mentions usually add noise and do not contribute to emotion prediction.\n",
    "\n",
    "3. Preserve emojis\n",
    "    * Emojis are strong emotional signals and should not be filtered out.\n",
    "\n",
    "4. Limit repeated characters to max 3\n",
    "    * Too many repeats confuse the tokenizer, but some repetition conveys emotional intensity.\n",
    "\n",
    "5. Collapse multiple spaces\n",
    "    * Makes the tokenizer cleaner and more efficient.\n",
    "\n",
    "6. Do not lowercase\n",
    "    * Uppercase text may convey emotion intensity.\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "1. Label Mapping (label2id / id2label)\n",
    "    * mappings are created for : \"label → id\" and \"id → label\"\n",
    "\n",
    "2. Class Weights\n",
    "    * The dataset is imbalanced, so we compute balanced class weights.\n",
    "    * This prevents the model from favoring majority classes.\n",
    "\n",
    "3. Extended max_length = 256\n",
    "    * Many posts are long and expressive, so longer sequences preserve emotional context.\n",
    "\n",
    "4. K-Fold Cross Validation\n",
    "    * Ensures stable training and evaluation across multiple splits.\n",
    "    * Helps with robustness and reduces overfitting.\n",
    "\n",
    "5. Tokenizer Feature Engineering\n",
    "    * Use RoBERTa tokenizer (strong for social-media-style English)\n",
    "    * Do not lowercase the text (uppercase conveys emotion)\n",
    "\n",
    "### 1.3 Explanation of Your Model\n",
    "1. RoBERTa-Large for Emotion Classification\n",
    "    * RoBERTa is a more robust variant of BERT, trained on more data.\n",
    "\n",
    "2. Weighted Cross-Entropy Loss\n",
    "    * Addresses class imbalance by giving minority classes higher importance.\n",
    "\n",
    "3. K-Fold Ensemble (N=5)\n",
    "    * Each fold trains a separate model.\n",
    "    * Ensemble prediction is based on averaging logits (soft voting).\n",
    "    * Ensembles typically outperform single-model setups.\n",
    "\n",
    "4. Warmup, Weight Decay, FP16 Training\n",
    "    * Warmup stabilizes the early training phase.\n",
    "    * Weight decay prevents overfitting.\n",
    "    * FP16 reduces memory usage and speeds up training.\n",
    "\n",
    "5. WeightedTrainer\n",
    "    * Extends HuggingFace Trainer to support class-weighted loss.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "**Add more detail in previous sections**\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "1. Trying different pretrained models\n",
    "    * I evaluated five models and recorded their Kaggle Public Scores\n",
    "    * ![PublicScore.png](./KaggleData/PublicScore.png)\n",
    "    * Observation\n",
    "        * Larger general-purpose models outperform emotion-specific ones.\n",
    "        * RoBERTa-Large provides the best and most stable performance.\n",
    "\n",
    "2. Hyperparameter tuning on RoBERTa-Large\n",
    "    * I explored many hyperparameter combinations and found the following setting to be optimal:\n",
    "        * MAX_LENGTH = 256\n",
    "        * EPOCHS = 12\n",
    "        * TRAIN_BATCH_SIZE = 16\n",
    "        * EVAL_BATCH_SIZE = 32\n",
    "        * LEARNING_RATE = 2e-5\n",
    "        * WARMUP_RATIO = 0.1\n",
    "        * WEIGHT_DECAY = 0.05\n",
    "        * USE_KFOLD = True\n",
    "        * N_FOLDS = 5\n",
    "    * Final public score: 0.6886\n",
    "\n",
    "3. K-Fold Cross Validation Ensemble\n",
    "    * I experimented with Single-model training and 5-Fold CV training, and 5-Fold CV has better result.\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "1. Larger models generalize better than emotion-specific ones\n",
    "    * Despite being domain-specific, emotion-specialized RoBERTa models still lose to roberta-large.\n",
    "    * Model capacity matters more than domain specialization.\n",
    "\n",
    "2. K-Fold ensembling improves stability and score\n",
    "    * Logit averaging reduces noise and overfitting, leading to higher leaderboard performance.\n",
    "\n",
    "3. Class weights significantly improve minority-class recall\n",
    "    * Especially for low-frequency labels like fear and surprise.\n",
    "    * Weighted loss makes the model treat all labels more equally.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 13:58:40.033824: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### Add the code related to the preprocessing steps in cells inside this section\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configurations for dataset and model\n",
    "\n",
    "DATA_DIR = \"KaggleData\"\n",
    "\n",
    "MODEL_NAME = \"roberta-large\"\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "EPOCHS = 12\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "EVAL_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.05\n",
    "\n",
    "USE_KFOLD = True\n",
    "N_FOLDS = 5\n",
    "\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, \"bert_optimized_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep emojis, repeated characters and normalize over-repeated characters\n",
    "\n",
    "def clean_text_improved(text: str) -> str:\n",
    "    text = str(text)\n",
    "\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text) \n",
    "    text = re.sub(r\"@\\w+\", \" \", text)             \n",
    "    text = re.sub(r'(.)\\1{3,}', r'\\1\\1\\1', text)  \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()      \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final_posts.json into a DataFrame\n",
    "\n",
    "def load_posts(json_path: str) -> pd.DataFrame:\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "    for item in data:\n",
    "        post = item[\"root\"][\"_source\"][\"post\"]\n",
    "        rows.append({\n",
    "            \"post_id\": post[\"post_id\"],\n",
    "            \"text\": post[\"text\"],\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load posts, merge with labels, merge with split info and apply improved text cleaning.\n",
    "\n",
    "def preprocessing(data_dir: str = DATA_DIR) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    print(\">>> Loading data...\")\n",
    "    posts = load_posts(os.path.join(data_dir, \"final_posts.json\"))\n",
    "    emotions = pd.read_csv(os.path.join(data_dir, \"emotion.csv\"))\n",
    "    split_info = pd.read_csv(os.path.join(data_dir, \"data_identification.csv\"))\n",
    "\n",
    "    emotions = emotions.rename(columns={\"id\": \"post_id\"})\n",
    "    split_info = split_info.rename(columns={\"id\": \"post_id\", \"split\": \"usage\"})\n",
    "\n",
    "    df = posts.merge(split_info, on=\"post_id\", how=\"inner\")\n",
    "    df = df.merge(emotions, on=\"post_id\", how=\"left\")\n",
    "\n",
    "    df = df.rename(columns={\"post_id\": \"id\", \"emotion\": \"label\"})\n",
    "\n",
    "    df[\"clean_text\"] = df[\"text\"].apply(clean_text_improved)\n",
    "\n",
    "    train_df = df[df[\"usage\"] == \"train\"].dropna(subset=[\"clean_text\", \"label\"]).copy()\n",
    "    test_df  = df[df[\"usage\"] == \"test\"].dropna(subset=[\"clean_text\"]).copy()\n",
    "\n",
    "    print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")\n",
    "    print(\"Label distribution:\", train_df[\"label\"].value_counts())\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the feature engineering steps in cells inside this section\n",
    "# Make label mapping\n",
    "\n",
    "def make_label_mapping(train_df: pd.DataFrame):\n",
    "    unique_labels = sorted(train_df[\"label\"].unique())\n",
    "    label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "    \n",
    "    print(\"Label mapping:\", label2id)\n",
    "    return label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "\n",
    "def compute_class_weights(train_df: pd.DataFrame, label2id: Dict[str, int]):\n",
    "    labels = train_df[\"label\"].map(label2id).values\n",
    "    \n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(labels),\n",
    "        y=labels\n",
    "    )\n",
    "    weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    \n",
    "    print(\"Class weights:\", weight_dict)\n",
    "    return weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "\n",
    "def prepare_datasets(train_texts, train_labels, eval_texts, eval_labels, \n",
    "                     test_texts, tokenizer, max_length):\n",
    "    train_df = pd.DataFrame({\"clean_text\": train_texts, \"labels\": train_labels})\n",
    "    eval_df  = pd.DataFrame({\"clean_text\": eval_texts,  \"labels\": eval_labels})\n",
    "    test_df  = pd.DataFrame({\"clean_text\": test_texts})\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    eval_dataset  = Dataset.from_pandas(eval_df)\n",
    "    test_dataset  = Dataset.from_pandas(test_df)\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(\n",
    "            batch[\"clean_text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "        )\n",
    "\n",
    "    train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "    eval_dataset  = eval_dataset.map(tokenize, batched=True)\n",
    "    test_dataset  = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "    train_dataset = train_dataset.remove_columns([\"clean_text\", \"__index_level_0__\"] if \"__index_level_0__\" in train_dataset.column_names else [\"clean_text\"])\n",
    "    eval_dataset  = eval_dataset.remove_columns([\"clean_text\", \"__index_level_0__\"] if \"__index_level_0__\" in eval_dataset.column_names else [\"clean_text\"])\n",
    "    test_dataset  = test_dataset.remove_columns([\"clean_text\", \"__index_level_0__\"] if \"__index_level_0__\" in test_dataset.column_names else [\"clean_text\"])\n",
    "\n",
    "    train_dataset.set_format(\"torch\")\n",
    "    eval_dataset.set_format(\"torch\")\n",
    "    test_dataset.set_format(\"torch\")\n",
    "\n",
    "    return train_dataset, eval_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the model implementation steps in cells inside this section\n",
    "# Define metrics\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    return {\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"micro_f1\": f1_score(labels, preds, average=\"micro\"),\n",
    "        \"weighted_f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Trainer\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        if self.class_weights is not None:\n",
    "            weights = torch.tensor(\n",
    "                list(self.class_weights.values()),\n",
    "                dtype=torch.float32\n",
    "            ).to(logits.device)\n",
    "\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "            loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        else:\n",
    "            loss = outputs.loss\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single model for K-Fold\n",
    "\n",
    "def train_single_model(train_dataset, eval_dataset, test_dataset,\n",
    "                       label2id, id2label, class_weights,\n",
    "                       output_dir, seed=42):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "        per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        \n",
    "        logging_steps=50,\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "        seed=seed,\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        class_weights=class_weights,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_result = trainer.evaluate()\n",
    "    print(\"Eval Macro F1:\", eval_result.get(\"eval_macro_f1\"))\n",
    "\n",
    "    preds = trainer.predict(test_dataset)\n",
    "    logits = preds.predictions\n",
    "    pred_ids = np.argmax(logits, axis=-1)\n",
    "    pred_labels = [id2label[i] for i in pred_ids]\n",
    "\n",
    "    return pred_labels, logits, eval_result.get(\"eval_macro_f1\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold training and logits-averaging ensemble\n",
    "\n",
    "def train_kfold(train_df, test_df, tokenizer):\n",
    "    label2id, id2label = make_label_mapping(train_df)\n",
    "    class_weights = compute_class_weights(train_df, label2id)\n",
    "\n",
    "    train_df[\"label_id\"] = train_df[\"label\"].map(label2id)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    all_logits = []\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df[\"label_id\"])):\n",
    "        print(f\"\\n===== Fold {fold+1}/{N_FOLDS} =====\")\n",
    "\n",
    "        train_texts = train_df.iloc[train_idx][\"clean_text\"].values\n",
    "        val_texts   = train_df.iloc[val_idx][\"clean_text\"].values\n",
    "        train_labels = train_df.iloc[train_idx][\"label_id\"].values\n",
    "        val_labels   = train_df.iloc[val_idx][\"label_id\"].values\n",
    "        test_texts   = test_df[\"clean_text\"].values\n",
    "\n",
    "        train_dataset, val_dataset, test_dataset = prepare_datasets(\n",
    "            train_texts, train_labels, val_texts, val_labels,\n",
    "            test_texts, tokenizer, MAX_LENGTH\n",
    "        )\n",
    "\n",
    "        pred_labels, logits, score = train_single_model(\n",
    "            train_dataset, val_dataset, test_dataset,\n",
    "            label2id, id2label, class_weights,\n",
    "            output_dir=os.path.join(OUTPUT_DIR, f\"fold_{fold}\"),\n",
    "            seed=42+fold\n",
    "        )\n",
    "\n",
    "        all_logits.append(logits)\n",
    "        fold_scores.append(score)\n",
    "\n",
    "    print(\"\\nK-Fold Results:\")\n",
    "    print(f\"Scores: {fold_scores}\")\n",
    "    print(f\"Mean: {np.mean(fold_scores)}, Std: {np.std(fold_scores)}\")\n",
    "\n",
    "    avg_logits = np.mean(all_logits, axis=0)\n",
    "    final_ids = np.argmax(avg_logits, axis=-1)\n",
    "    final_labels = [id2label[i] for i in final_ids]\n",
    "\n",
    "    return final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline execution\n",
    "\n",
    "train_df, test_df = preprocessing(DATA_DIR)\n",
    "\n",
    "print(\"\\nLoading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"\\nUsing {N_FOLDS}-Fold Cross Validation...\")\n",
    "predictions = train_kfold(train_df, test_df, tokenizer)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"].values,\n",
    "    \"emotion\": predictions,\n",
    "})\n",
    "\n",
    "output_path = os.path.join(DATA_DIR, \"submission_.csv\")\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_lab2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
